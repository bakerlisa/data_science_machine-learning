{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_Metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VKCGFx-3u6Nt5MBAScmBz5NtPaV34Mab",
      "authorship_tag": "ABX9TyMGgk7HIfbZHRx0BUrajq0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lisabroadhead/data_science_machine-learning/blob/main/Classification_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lisa Broadhead\n",
        "- July 5, 2022"
      ],
      "metadata": {
        "id": "o0aAJFpBHiT4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIBuSj1RW_JB"
      },
      "source": [
        "# Classification Metrics:\n",
        "\n",
        "\n",
        "![target image](https://github.com/ninja-josh/image-storage/raw/main/qft5tas90c801%20(1).jpeg)\n",
        "\n",
        "## How do we know if our model is any good?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2edK4bNx-5Y"
      },
      "source": [
        "## Regression vs Classification Metrics\n",
        "\n",
        "### Regression Metrics\n",
        "\n",
        "In a regression model a target label could have any value (theoretically).\n",
        "\n",
        "When we are creating a regression model, we try to create a model that predicts a label that is as close to the true label value for a sample as possible.  This is why we use metrics like mean absolute error, mean squared error, or root mean squared error.  We want to know how far away the prediction from the truth.  In fact, our model may never make a perfectly accurate prediction and that's fine, as long as it is close enough.\n",
        "\n",
        "### Classification Metrics\n",
        "\n",
        "With classification models each sample is a member of one of a finite number of classes.  For each sample, either the model predicts the correct class or predicts one of the incorrect classes.  It's right or wrong, there is no 'close'.\n",
        "\n",
        "Because of this we need different metrics.  In this lesson we will explore how to evaluate a classification model using:\n",
        "\n",
        "1. Accuracy\n",
        "2. Precision\n",
        "3. Recall\n",
        "4. A Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MEED0E4ZHJO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import seaborn to make a nice heatmap for our confusion matrix\n",
        "import seaborn as sns\n",
        "\n",
        "#import some necessary tools\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "#import accuracy, precision, recall, classification report, and confusion matrix scoring functions\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "#Importing the Classifiers\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghZG2YZV2lLW"
      },
      "source": [
        "'Breast Cancer Wisconsin' is a binary classification dataset that comes with the sklearn package in order to demonstrate and experiment with models.  We will use this well studied and pre-cleaned dataset to demonstrate how to evaluate a classification model on a binary classification problem.  Each record in this dataset is a mass in a breast and each feature is a measurement of that mass.  The target is 0 = benign, or 1 = malignant.\n",
        "\n",
        "Our task will be to create a model that classifies a given mass as either benign or malignant.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbwkH-kG2XU6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "255c9fd2-dc29-4edf-f473-a8a29abe6265"
      },
      "source": [
        "#Load the Data\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "y = pd.DataFrame(data.target, columns=['outcome'])\n",
        "print(y.value_counts(normalize=True))\n",
        "X.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "outcome\n",
            "1          0.627417\n",
            "0          0.372583\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0        17.99         10.38          122.80     1001.0          0.11840   \n",
              "1        20.57         17.77          132.90     1326.0          0.08474   \n",
              "2        19.69         21.25          130.00     1203.0          0.10960   \n",
              "3        11.42         20.38           77.58      386.1          0.14250   \n",
              "4        20.29         14.34          135.10     1297.0          0.10030   \n",
              "\n",
              "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0           0.27760          0.3001              0.14710         0.2419   \n",
              "1           0.07864          0.0869              0.07017         0.1812   \n",
              "2           0.15990          0.1974              0.12790         0.2069   \n",
              "3           0.28390          0.2414              0.10520         0.2597   \n",
              "4           0.13280          0.1980              0.10430         0.1809   \n",
              "\n",
              "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
              "0                 0.07871  ...         25.38          17.33           184.60   \n",
              "1                 0.05667  ...         24.99          23.41           158.80   \n",
              "2                 0.05999  ...         23.57          25.53           152.50   \n",
              "3                 0.09744  ...         14.91          26.50            98.87   \n",
              "4                 0.05883  ...         22.54          16.67           152.20   \n",
              "\n",
              "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
              "0      2019.0            0.1622             0.6656           0.7119   \n",
              "1      1956.0            0.1238             0.1866           0.2416   \n",
              "2      1709.0            0.1444             0.4245           0.4504   \n",
              "3       567.7            0.2098             0.8663           0.6869   \n",
              "4      1575.0            0.1374             0.2050           0.4000   \n",
              "\n",
              "   worst concave points  worst symmetry  worst fractal dimension  \n",
              "0                0.2654          0.4601                  0.11890  \n",
              "1                0.1860          0.2750                  0.08902  \n",
              "2                0.2430          0.3613                  0.08758  \n",
              "3                0.2575          0.6638                  0.17300  \n",
              "4                0.1625          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82937242-cccd-4ec5-9edd-3cbb514f9917\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82937242-cccd-4ec5-9edd-3cbb514f9917')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82937242-cccd-4ec5-9edd-3cbb514f9917 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82937242-cccd-4ec5-9edd-3cbb514f9917');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5KB8Y5i2gS9"
      },
      "source": [
        "#Train-test split.  Set the random state to 42\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVPyRoxE7xdd"
      },
      "source": [
        "# Baseline vs Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg6ogWgM7W3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4735a9-1e82-4eb6-e2b0-68e0a761ad04"
      },
      "source": [
        "#Create a DecisionTreeClassifier model\n",
        "dec_tree = DecisionTreeClassifier(random_state  = 42)\n",
        "\n",
        "#Create a DummyClassifier model using the 'most_frequent' strategy\n",
        "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "\n",
        "#Fit both models on the training data and save their predictions on the test sets\n",
        "dec_tree.fit(X_train, y_train)\n",
        "dummy_clf.fit(X_train, y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DummyClassifier(strategy='most_frequent')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = dec_tree.predict(X_test)\n",
        "dum_preds =  dummy_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "OwO90SpggDxT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEr-cVH9O0ND"
      },
      "source": [
        "Quickly remind yourself of what you learned about type 1 and type 2 errors.  In every binary classification problem we select one class to be the **'positive'** class and one to be the **'negative'** class.  The positive class should be the one you are most interested in finding.  For our breast cancer dataset the positive class will be the malignant masses and the negative class will be the benign one.\n",
        "\n",
        "## Type 1 error:\n",
        "If our model predicts that a mass is malignant, but it is in fact benign, it will have made a type 1 error.  This is also known as a false positive\n",
        "\n",
        "## Type 2 error:\n",
        "If our model predicts that a mass is benign, when in fact it is malignant, it will have made a type 2 error.  This is is also known as a false negative.\n",
        "\n",
        "\n",
        "*Which of these do you think is worse in this case?  If we have to increase one kind of error in order to minimize the other kind, which would we want to minimize?  Why?*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ--mFdZN21E"
      },
      "source": [
        "# Accuracy\n",
        "\n",
        "Accuracy is the metric that is most intuitive.  This is defined as:\n",
        "\n",
        "$$\n",
        "accuracy = \\frac{True  Positives + True  Negatives}{All  Samples}\n",
        "$$\n",
        "\n",
        "In other words accuracy is correct predictions our model made out of the total number of predictions.\n",
        "\n",
        "Pros:\n",
        "Accuracy is easy to understand and gives a combined picture of both kinds of errors in one number.\n",
        "\n",
        "Cons: Accuracy can be deceiving when a dataset is unbalanced.  It also does not give specific information about the kinds of errors that a model is making.\n",
        "\n",
        "For example, we saw above that 62% of our samples are malign masses when we did `y.value_counts(normalize=True)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3p1w80pNXKM"
      },
      "source": [
        "To use the sklearn metrics functions we pass them first the true labels, then the predicted labels.  For example: `accuracy = accuracy_score(y_test, y_pred)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iAa_70TNw_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4fabff6-30e7-4bee-8fcb-25f2149551d0"
      },
      "source": [
        "##### ========== CHECK ==========\n",
        "# Print the accuracy of both models on the test set\n",
        "dec_acc_score = accuracy_score(y_test, preds)\n",
        "dum_acc_score = accuracy_score(y_test, dum_preds)\n",
        "\n",
        "print(dec_acc_score)\n",
        "print(dum_acc_score)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.951048951048951\n",
            "0.6223776223776224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2c7ChhLV2cT"
      },
      "source": [
        "If our dataset were even more imbalanced, say 99.9% malignant, then a prediction that EVERYTHING is malignant would have a very high accuracy.  However, that would not be a very useful model for actual medical use.  More often we see the opposite: a disease is very rare, occurring .01% of the time or less, and a model that predicts that NO samples ever have the disease will have a high accuracy, but will actually be useless...and dangerous!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKCBKNtvUQae"
      },
      "source": [
        "# Recall\n",
        "\n",
        "When we want to reduce the number of false negatives, we want to improve recall.\n",
        "\n",
        "Recall is defined as: \n",
        "\n",
        "$$\n",
        "recall = \\frac{True Positives}{False Negatives + True Positives}\n",
        "$$\n",
        "\n",
        "That is to say: how many samples did our model label as positive out of all of the true positive samples?\n",
        "\n",
        "Pros: A higher recall means a fewer false negative predictions, also known as type 2 errors.  It's great for when classifying a positive as a negative is a costly mistake.\n",
        "\n",
        "Cons: Does not consider how many samples are falsely labeled as positive, or false positives.  It does not penalize type 1 errors.\n",
        "\n",
        "In the case of this dataset, we might assume that the consequence for a false negative is that a person needlessly dies from cancer while the consequence for a false positive is that someone has unnecessary surgery.  While neither is great, the second is generally going to be less bad.  A high recall means fewer malignant masses going untreated.\n",
        "\n",
        "You can use the Scikit-Learn function: `metrics.recall_score()` to calcuate this.  Check the documentation on this function for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwboFujvYHSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d924401-42c2-4bb1-c99e-623f2f71b724"
      },
      "source": [
        "#Print the recall scores of both models.\n",
        "train_score = dec_tree.score(X_train, y_train)\n",
        "test_score = dec_tree.score(X_test, y_test)\n",
        "print(train_score)\n",
        "print(test_score)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "0.951048951048951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dum_score = dummy_clf.score(X_train, y_train)\n",
        "test_dum_score = dummy_clf.score(X_test, y_test)\n",
        "print(train_dum_score)\n",
        "print(test_dum_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n-Gz2-3h1Bv",
        "outputId": "cc3d59db-eb74-4b5e-bb2a-360d4c7421f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6291079812206573\n",
            "0.6223776223776224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyM5xz6lYWTg"
      },
      "source": [
        "\n",
        "You can see that our Decision Tree model has a high recall, but just predicting that ALL tumors are malignant gives us a perfect recall of 1!  While we want to catch as many malignant tumors as possible, we don't want to just send everyone under the knife, especially since we know that 38% don't need surgery!\n",
        "\n",
        "# Precision\n",
        "\n",
        "When we want to reduce the number of false positives, we want to improve precision.\n",
        "\n",
        "Precision is defined as:\n",
        "\n",
        "$$\n",
        "precision = \\frac{True Positives}{False Positives + True Positives}\n",
        "$$\n",
        "\n",
        "In other words: What ratio of the samples that we predicted were in the positive class were actually in the positive class?\n",
        "\n",
        "Pros:  A high precision means fewer type 1 errors, or fewer false positives.  This is a good metric to maximize if a false positive prediction is a costly mistake.\n",
        "\n",
        "Cons: Precision does not penalize a model for false negatives.  It does not count type 2 errors.\n",
        "\n",
        "In this case precision would be measuring how many of the tumors we elected to operate on were actually malignant.\n",
        "\n",
        "You can use the Scikit-Learn function: `metrics.precision_score()` to calculate this.  Check the documentation on this function for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjuf4fvJajS-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7594fe30-849d-4184-c357-9256e8b1d51b"
      },
      "source": [
        "##### ========== CHECK ==========\n",
        "#Print the precision scores of both models.\n",
        "print(metrics.precision_score(y_test, preds))\n",
        "print(metrics.precision_score(y_test, dum_preds))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9659090909090909\n",
            "0.6223776223776224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "63r8tnYaoNGT",
        "outputId": "cba4783f-9158-4435-9f4a-e3904509801a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "287       12.890         13.12           81.89      515.9          0.06955   \n",
              "512       13.400         20.52           88.64      556.7          0.11060   \n",
              "402       12.960         18.29           84.18      525.2          0.07351   \n",
              "446       17.750         28.03          117.30      981.6          0.09997   \n",
              "210       20.580         22.14          134.70     1290.0          0.09090   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "71         8.888         14.64           58.79      244.0          0.09783   \n",
              "106       11.640         18.33           75.17      412.5          0.11420   \n",
              "270       14.290         16.82           90.30      632.6          0.06429   \n",
              "435       13.980         19.62           91.12      599.5          0.10600   \n",
              "102       12.180         20.52           77.22      458.7          0.08013   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "287           0.03729         0.02260              0.01171         0.1337   \n",
              "512           0.14690         0.14450              0.08172         0.2116   \n",
              "402           0.07899         0.04057              0.01883         0.1874   \n",
              "446           0.13140         0.16980              0.08293         0.1713   \n",
              "210           0.13480         0.16400              0.09561         0.1765   \n",
              "..                ...             ...                  ...            ...   \n",
              "71            0.15310         0.08606              0.02872         0.1902   \n",
              "106           0.10170         0.07070              0.03485         0.1801   \n",
              "270           0.02675         0.00725              0.00625         0.1508   \n",
              "435           0.11330         0.11260              0.06463         0.1669   \n",
              "102           0.04038         0.02383              0.01770         0.1739   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "287                 0.05581  ...        13.620          15.54   \n",
              "512                 0.07325  ...        16.410          29.66   \n",
              "402                 0.05899  ...        14.130          24.61   \n",
              "446                 0.05916  ...        21.530          38.54   \n",
              "210                 0.05024  ...        23.240          27.84   \n",
              "..                      ...  ...           ...            ...   \n",
              "71                  0.08980  ...         9.733          15.67   \n",
              "106                 0.06520  ...        13.140          29.26   \n",
              "270                 0.05376  ...        14.910          20.65   \n",
              "435                 0.06544  ...        17.040          30.80   \n",
              "102                 0.05677  ...        13.340          32.84   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "287            87.40       577.0           0.09616            0.11470   \n",
              "512           113.30       844.4           0.15740            0.38560   \n",
              "402            96.31       621.9           0.09329            0.23180   \n",
              "446           145.40      1437.0           0.14010            0.37620   \n",
              "210           158.30      1656.0           0.11780            0.29200   \n",
              "..               ...         ...               ...                ...   \n",
              "71             62.56       284.4           0.12070            0.24360   \n",
              "106            85.51       521.7           0.16880            0.26600   \n",
              "270            94.44       684.6           0.08567            0.05036   \n",
              "435           113.90       869.3           0.16130            0.35680   \n",
              "102            84.58       547.8           0.11230            0.08862   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "287          0.11860               0.05366          0.2309   \n",
              "512          0.51060               0.20510          0.3585   \n",
              "402          0.16040               0.06608          0.3207   \n",
              "446          0.63990               0.19700          0.2972   \n",
              "210          0.38610               0.19200          0.2909   \n",
              "..               ...                   ...             ...   \n",
              "71           0.14340               0.04786          0.2254   \n",
              "106          0.28730               0.12180          0.2806   \n",
              "270          0.03866               0.03333          0.2458   \n",
              "435          0.40690               0.18270          0.3179   \n",
              "102          0.11450               0.07431          0.2694   \n",
              "\n",
              "     worst fractal dimension  \n",
              "287                  0.06915  \n",
              "512                  0.11090  \n",
              "402                  0.07247  \n",
              "446                  0.09075  \n",
              "210                  0.05865  \n",
              "..                       ...  \n",
              "71                   0.10840  \n",
              "106                  0.09097  \n",
              "270                  0.06120  \n",
              "435                  0.10550  \n",
              "102                  0.06878  \n",
              "\n",
              "[426 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a53ec57d-e71e-4a95-adb9-617bd31c1bb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>12.890</td>\n",
              "      <td>13.12</td>\n",
              "      <td>81.89</td>\n",
              "      <td>515.9</td>\n",
              "      <td>0.06955</td>\n",
              "      <td>0.03729</td>\n",
              "      <td>0.02260</td>\n",
              "      <td>0.01171</td>\n",
              "      <td>0.1337</td>\n",
              "      <td>0.05581</td>\n",
              "      <td>...</td>\n",
              "      <td>13.620</td>\n",
              "      <td>15.54</td>\n",
              "      <td>87.40</td>\n",
              "      <td>577.0</td>\n",
              "      <td>0.09616</td>\n",
              "      <td>0.11470</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.05366</td>\n",
              "      <td>0.2309</td>\n",
              "      <td>0.06915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>13.400</td>\n",
              "      <td>20.52</td>\n",
              "      <td>88.64</td>\n",
              "      <td>556.7</td>\n",
              "      <td>0.11060</td>\n",
              "      <td>0.14690</td>\n",
              "      <td>0.14450</td>\n",
              "      <td>0.08172</td>\n",
              "      <td>0.2116</td>\n",
              "      <td>0.07325</td>\n",
              "      <td>...</td>\n",
              "      <td>16.410</td>\n",
              "      <td>29.66</td>\n",
              "      <td>113.30</td>\n",
              "      <td>844.4</td>\n",
              "      <td>0.15740</td>\n",
              "      <td>0.38560</td>\n",
              "      <td>0.51060</td>\n",
              "      <td>0.20510</td>\n",
              "      <td>0.3585</td>\n",
              "      <td>0.11090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>12.960</td>\n",
              "      <td>18.29</td>\n",
              "      <td>84.18</td>\n",
              "      <td>525.2</td>\n",
              "      <td>0.07351</td>\n",
              "      <td>0.07899</td>\n",
              "      <td>0.04057</td>\n",
              "      <td>0.01883</td>\n",
              "      <td>0.1874</td>\n",
              "      <td>0.05899</td>\n",
              "      <td>...</td>\n",
              "      <td>14.130</td>\n",
              "      <td>24.61</td>\n",
              "      <td>96.31</td>\n",
              "      <td>621.9</td>\n",
              "      <td>0.09329</td>\n",
              "      <td>0.23180</td>\n",
              "      <td>0.16040</td>\n",
              "      <td>0.06608</td>\n",
              "      <td>0.3207</td>\n",
              "      <td>0.07247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>17.750</td>\n",
              "      <td>28.03</td>\n",
              "      <td>117.30</td>\n",
              "      <td>981.6</td>\n",
              "      <td>0.09997</td>\n",
              "      <td>0.13140</td>\n",
              "      <td>0.16980</td>\n",
              "      <td>0.08293</td>\n",
              "      <td>0.1713</td>\n",
              "      <td>0.05916</td>\n",
              "      <td>...</td>\n",
              "      <td>21.530</td>\n",
              "      <td>38.54</td>\n",
              "      <td>145.40</td>\n",
              "      <td>1437.0</td>\n",
              "      <td>0.14010</td>\n",
              "      <td>0.37620</td>\n",
              "      <td>0.63990</td>\n",
              "      <td>0.19700</td>\n",
              "      <td>0.2972</td>\n",
              "      <td>0.09075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>20.580</td>\n",
              "      <td>22.14</td>\n",
              "      <td>134.70</td>\n",
              "      <td>1290.0</td>\n",
              "      <td>0.09090</td>\n",
              "      <td>0.13480</td>\n",
              "      <td>0.16400</td>\n",
              "      <td>0.09561</td>\n",
              "      <td>0.1765</td>\n",
              "      <td>0.05024</td>\n",
              "      <td>...</td>\n",
              "      <td>23.240</td>\n",
              "      <td>27.84</td>\n",
              "      <td>158.30</td>\n",
              "      <td>1656.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.29200</td>\n",
              "      <td>0.38610</td>\n",
              "      <td>0.19200</td>\n",
              "      <td>0.2909</td>\n",
              "      <td>0.05865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>8.888</td>\n",
              "      <td>14.64</td>\n",
              "      <td>58.79</td>\n",
              "      <td>244.0</td>\n",
              "      <td>0.09783</td>\n",
              "      <td>0.15310</td>\n",
              "      <td>0.08606</td>\n",
              "      <td>0.02872</td>\n",
              "      <td>0.1902</td>\n",
              "      <td>0.08980</td>\n",
              "      <td>...</td>\n",
              "      <td>9.733</td>\n",
              "      <td>15.67</td>\n",
              "      <td>62.56</td>\n",
              "      <td>284.4</td>\n",
              "      <td>0.12070</td>\n",
              "      <td>0.24360</td>\n",
              "      <td>0.14340</td>\n",
              "      <td>0.04786</td>\n",
              "      <td>0.2254</td>\n",
              "      <td>0.10840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>11.640</td>\n",
              "      <td>18.33</td>\n",
              "      <td>75.17</td>\n",
              "      <td>412.5</td>\n",
              "      <td>0.11420</td>\n",
              "      <td>0.10170</td>\n",
              "      <td>0.07070</td>\n",
              "      <td>0.03485</td>\n",
              "      <td>0.1801</td>\n",
              "      <td>0.06520</td>\n",
              "      <td>...</td>\n",
              "      <td>13.140</td>\n",
              "      <td>29.26</td>\n",
              "      <td>85.51</td>\n",
              "      <td>521.7</td>\n",
              "      <td>0.16880</td>\n",
              "      <td>0.26600</td>\n",
              "      <td>0.28730</td>\n",
              "      <td>0.12180</td>\n",
              "      <td>0.2806</td>\n",
              "      <td>0.09097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>14.290</td>\n",
              "      <td>16.82</td>\n",
              "      <td>90.30</td>\n",
              "      <td>632.6</td>\n",
              "      <td>0.06429</td>\n",
              "      <td>0.02675</td>\n",
              "      <td>0.00725</td>\n",
              "      <td>0.00625</td>\n",
              "      <td>0.1508</td>\n",
              "      <td>0.05376</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>20.65</td>\n",
              "      <td>94.44</td>\n",
              "      <td>684.6</td>\n",
              "      <td>0.08567</td>\n",
              "      <td>0.05036</td>\n",
              "      <td>0.03866</td>\n",
              "      <td>0.03333</td>\n",
              "      <td>0.2458</td>\n",
              "      <td>0.06120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>13.980</td>\n",
              "      <td>19.62</td>\n",
              "      <td>91.12</td>\n",
              "      <td>599.5</td>\n",
              "      <td>0.10600</td>\n",
              "      <td>0.11330</td>\n",
              "      <td>0.11260</td>\n",
              "      <td>0.06463</td>\n",
              "      <td>0.1669</td>\n",
              "      <td>0.06544</td>\n",
              "      <td>...</td>\n",
              "      <td>17.040</td>\n",
              "      <td>30.80</td>\n",
              "      <td>113.90</td>\n",
              "      <td>869.3</td>\n",
              "      <td>0.16130</td>\n",
              "      <td>0.35680</td>\n",
              "      <td>0.40690</td>\n",
              "      <td>0.18270</td>\n",
              "      <td>0.3179</td>\n",
              "      <td>0.10550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>12.180</td>\n",
              "      <td>20.52</td>\n",
              "      <td>77.22</td>\n",
              "      <td>458.7</td>\n",
              "      <td>0.08013</td>\n",
              "      <td>0.04038</td>\n",
              "      <td>0.02383</td>\n",
              "      <td>0.01770</td>\n",
              "      <td>0.1739</td>\n",
              "      <td>0.05677</td>\n",
              "      <td>...</td>\n",
              "      <td>13.340</td>\n",
              "      <td>32.84</td>\n",
              "      <td>84.58</td>\n",
              "      <td>547.8</td>\n",
              "      <td>0.11230</td>\n",
              "      <td>0.08862</td>\n",
              "      <td>0.11450</td>\n",
              "      <td>0.07431</td>\n",
              "      <td>0.2694</td>\n",
              "      <td>0.06878</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>426 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a53ec57d-e71e-4a95-adb9-617bd31c1bb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a53ec57d-e71e-4a95-adb9-617bd31c1bb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a53ec57d-e71e-4a95-adb9-617bd31c1bb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOB0phAWbCSQ"
      },
      "source": [
        "# The Complete Picture: Confusion Matrices and classification_report()\n",
        "\n",
        "As you have seen, precision, precision, and recall each only tell part of the story.  In order to get the full picture of how your model is performing and what kinds of mistakes it tends to make, you need to look at a confusion matrix and/or sklearn's handy `classification_report()` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXAJ2jpZbt0i"
      },
      "source": [
        "Use ConfusionMatrixDisplay to display a confusion matrix of the model predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hAfxnzCbse5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2603c826-d3d9-4118-a656-b32150eb6f20"
      },
      "source": [
        "logreg_pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "\n",
        "logreg_pipe.fit(X_train, y_train)\n",
        "predictions = logreg_pipe.predict(X_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test.values, predictions)\n",
        "cm_df = pd.DataFrame(cm)"
      ],
      "metadata": {
        "id": "r8GWX4Utpu8q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=['Benign','Malignant']\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, predictions, display_labels=labels, cmap='Blues');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "M0b4bn2-pwxk",
        "outputId": "18c8ad53-2dbb-4203-ebf1-e73f7384b80f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1nZ-FEKcIfx"
      },
      "source": [
        "We see the false positives predictions (top right) and false negative predictions (bottom left) that our model made.  However, the bottom left is out of 89 total and the top right is out of 54 total.  We can see the normalized ratios of true and false predictions by normalizing along the 'true' or 'pred' axes in the ConfusionMatrixDisplay.  \n",
        "\n",
        "To normalize along the 'true' axis, we set  normalize = 'true'`.  \n",
        "\n",
        "Notice that it is the string 'true' NOT the boolean value: `True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B20cEmYb4oB"
      },
      "source": [
        "#Recreate the confusion matrix above, but with the values normalized along the 'true' axis.\n",
        "cm1 = confusion_matrix(y_test.values, predictions, normalize = 'true')\n",
        "cm1_df = pd.DataFrame(cm)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels=['Benign','Malignant']\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, predictions, display_labels=labels, cmap='Blues');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "s5_u1bbjqEA5",
        "outputId": "47bbb098-60ea-4575-8644-307f38e72199"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAEGCAYAAADGwUaDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAex0lEQVR4nO3de7xVVb338c93b0QQEUGMSCswSfKKgnh7UrymaGnlo9LlheXJ7OaxXnWi0zlidlE7Pcc06yRqJzyaeU9K8xJHM8tQQBQEDPMWinIRTBBR4Pf8McfW5Q7Wnpu91lxrT77vXvO153XM394rf4w15hxjKCIwM7NitDQ6ADOzzYmTrplZgZx0zcwK5KRrZlYgJ10zswL1aHQA3VXPrbeN3tsNbnQY1gk7D+zT6BCsE55++imWLl2qrpTRus27I9auznVurF5yR0Qc3ZX75eGku4l6bzeYAyf8vNFhWCfc/Jn9Gh2CdcJB+43qchmxdjVb7nJSrnNfnfXjgV2+YQ5OumZWYgI1Vyuqk66ZlZeAltZGR/EWTrpmVm7qUrNwzTnpmlmJuXnBzKxYrumamRVEuKZrZlYcuaZrZlYov71gZlYUP0gzMyuOcPOCmVmhXNM1MyuKmxfMzIojoLW5HqQ11z8BZma1JuVbchWlL0t6VNIcSddI6iVpqKRpkh6XdK2kntXKcNI1sxJLzQt5lo5KknYAzgRGRcTuQCtwCnABcGFE7AwsB06rVo6TrpmVWw1rumRNsr0l9QC2AhYBhwE3pOOTgROqFeCka2bllr+mO1DS9Irl9MpiIuJZ4AfAM2TJ9iVgBrAiItam0xYCO1QLxw/SzKy8OleLXRoRG52uQlJ/4HhgKLACuB7o9PQ+TrpmVm616wZ8BPBkRCwBkHQTcBCwraQeqba7I/Bs1XBqFY2ZWfOp3YM0smaF/SVtJUnA4cBc4G7gxHTOeOCWaoU46ZpZudXoQVpETCN7YDYTmE2WPycBXwe+IulxYDvgimrluHnBzMqrxuPpRsREYGK73U8Ao/OW4aRrZiXmbsBmZsXyeLpmZgXy0I5mZgWRmxfMzIrlmq6ZWXHkpGtmVoxsth4nXTOzYkioxUnXzKwwrumamRXISdfMrEBOumZmRVFamoiTrpmVlpBrumZmRWppcY80M7PCuKZrZlaUJmzTba56t5lZjUnKteQoZxdJsyqWv0s6S9IASXdJWpB+9q9WjpOumZVW24O0WiTdiHgsIkZExAhgJPAKcDMwAZgaEcOAqWl7o5x0zazU1KJcSycdDvw1Ip4mm5Z9cto/GTih2oVu0zWz8lKnHqQNlDS9YntSREzayLmnANek9UERsSitPw8MqnYTJ10zK7VOJN2lETEqR3k9gQ8B32h/LCJCUlS73s0LZlZqtWrTrXAMMDMiXkjbL0ganO41GFhc7WInXTMrrVo+SKswjjebFgCmAOPT+njglmoXO+maWbkp55KnKKkPcCRwU8Xu84EjJS0AjkjbG+U2XTMrL9W2G3BErAK2a7dvGdnbDLk46ZpZqbkbsJlZkZor5zrpbu4uPWUEq19fx/oI1q0PvvarRxk3ckdGv7s/QfDS6rVc/Pu/svyV1xsdqrXzxXOv4o775jCwf1/uv/abjQ6nabmmm4OkdcBssn+j1gFfjIg/bWJZ5wL3RsTvahhiqfz7b+bx8pq1b2z/6pFFXDNjIQDH7jaIk/fZgZ/e91SDorONGXfc/nzmpEM4Y+KVjQ6laW3Cmwl115RJF1id+jcj6QPAecAhm1JQRJxdy8A2B6tfX/fG+pY9Womqr3pboxy0z84889yyRofR9Jx0O28bYHnbhqSvAScBWwI3R8RESUOA3wL3AQcCzwLHR8RqST8HfhMRN0gaC/wnsAr4I7BTRBwn6RzgXcBO6ecPI+LiYn69xgqCiWOHQ8Ad81/grvlLAPj4qB0ZM2wgr7y2jn+/dV6DozTbdJ6CPZ/ekmYBvYDBwGEAko4ChgGjyZoepkg6GHgm7R8XEZ+RdB3wUeCqtgIl9QIuBQ6OiCclVb7cDDAcOBToCzwm6b8i4i0NmZJOB04H6DXg7TX+lRvjX6fM5cVXXqdfrx5MHDucZ1e8ytznX+bq6Qu5evpCPrLXOxi76yB+OfPZRodqtkmarabbrJ0jVqch1IYDRwNXKvvLHZWWh4CZZIlyWLrmyYiYldZnAEPalTkceCIinkzb7ZPurRGxJiKWknXj+4dBKyJiUkSMiohRPbfetmu/YZN4MT0ge+nVtUx7ajnDtu/zluP3Pr6UA4YOaERoZl2nunQD7pJmTbpviIj7gYHA9mS12/PaxrSMiJ0j4op06pqKy9bR+Vp8V6/vdrbs0UKvLVreWB+xYz+eWb6awdts+cY5o4f0Z+GKVxsVolmXCJDyLUVp+sQiaTjQCiwD7gC+LenqiFgpaQcg77tMjwE7SRoSEU8BJ9cl4G5k295b8PUjsy8KrS3iD48v46GFL/EvRwxjh369WB+wZOUafnrfkx2UZI1w2jf/mz/OWMCyFSvZ7dh/Y8LpY/nk8Qc2Oqwm47cX8mpr04XsH6vxEbEOuFPS+4D70x9yJfAJspppVemh2ueB2yWtAh6sT+jdxwsvr+ErN835h/3f/92CBkRjnXXFdz/V6BC6hRY/SOtYRLRWOXYRcNEGDu1ecc4PKtZPrTjn7ogYntqHfwxMT+ec0+4eu2Nm3V/BTQd5NGXSraPPSBoP9CR7GHdpg+MxszoSruk2VERcCFzY6DjMrDiu6ZqZFcgP0szMitKEbbpN/56umdmmEqKlpSXXkqs8aVtJN0iaL2mepAMkDZB0l6QF6Wf/amU46ZpZqdW4c8RFwO2pt+xewDxgAjA1IoYBU9P2Rjnpmlmp1aobsKR+wMHAFQAR8VpErACOByan0yYDJ1Qrx0nXzMorZy03Z013KLAE+G9JD0m6PE1UOSgiFqVznmcD47ZUctI1s9LKxl7IXdMdKGl6xXJ6u+J6APsA/xURe5MNEfuWpoSICKDqCNR+e8HMSq0T7bVLI2JUleMLgYURMS1t30CWdF+QNDgiFkkaTDZK4Ua5pmtmpdbSolxLRyLieeBvknZJuw4H5gJTgPFp33jglmrluKZrZuWlmneO+BJwtaSewBPAp8gqr9dJOg14mmxmm41y0jWz0mobT7dW0kQJG2qCODxvGU66ZlZiHk/XzKxQTZZznXTNrMTkoR3NzArT9p5uM3HSNbNSc9I1MytQk+VcJ10zKzfXdM3MitKEg5g76ZpZaWWDmDdX1nXSNbNSa2myqq6TrpmVWpPlXCddMysv1X7Amy5z0jWzUmuyJt2NJ11JP6LKCOgRcWZdIjIzq6Hu9CBtemFRmJnVgcjeYGgmG026ETG5clvSVhHxSv1DMjOrnSar6HY8XY+kAyTNBean7b0k/aTukZmZdVXOSSmLfNiWZ460HwIfAJYBRMTDZHO/m5k1vRpOwY6kpyTNljRL0vS0b4CkuyQtSD/7Vysj18SUEfG3drvW5QvRzKxxRNY5Is/SCYdGxIiKmYMnAFMjYhgwlXbTsreXJ+n+TdKBQEjaQtJXgXmdidDMrFFqNRtwFccDbc/AJgMnVI0nR4FnAF8AdgCeA0akbTOzppa3aSFVdAdKml6xnL6BIgO4U9KMiuODImJRWn8eGFQtpg47R0TEUuDjuX9LM7Mm0ommg6UVTQYb838i4llJbwPukjS/8mBEhKSN9m+AfG8v7CTp15KWSFos6RZJO3Ucv5lZ4ynnkkdEPJt+LgZuBkYDL0gaDJB+Lq5WRp7mhV8A1wGDgXcA1wPX5IzRzKyhavXKmKQ+kvq2rQNHAXOAKcD4dNp44JZq5eQZe2GriPifiu2rJH0tx3VmZg2Vvb1Qs+IGATenBN0D+EVE3C7pQeA6SacBTwMnVSuk2tgLA9LqbyVNAH5J1oh8MnBb1+M3M6sz1W4Q84h4AthrA/uXAYfnLadaTXcGWZJti/izlfcBvpH3JmZmjdJthnaMiKFFBmJmVms1bl6oiVzj6UraHdgV6NW2LyKurFdQZma10m1qum0kTQTGkCXd24BjgPsAJ10za3rNlXLzvTJ2Ilkj8fMR8SmyhuR+dY3KzKwGJGhtUa6lKHmaF1ZHxHpJayVtQ/bi7zvrHJeZWU10u+YFYLqkbYHLyN5oWAncX9eozMxqpMlybq6xFz6fVn8q6XZgm4h4pL5hmZl1nej0sI11V61zxD7VjkXEzPqEZGZWI50YoLwo1Wq6/6/KsQAOq3Es3cp7BvbhxtNGNzoM64T++36x0SFYJ6x57JmalNNt2nQj4tAiAzEzqzUBrd0l6ZqZlUG37JFmZtZdOemamRUkm4qnubJunpkjJOkTks5O2++S5CdIZtYttCjfUlg8Oc75CXAAMC5tvwz8uG4RmZnVUCcmpixEnqS7X0R8AXgVICKWAz3rGpWZWQ0I6CHlWnKVJ7VKekjSb9L2UEnTJD0u6VpJHebGPEn3dUmtZO/mIml7YH2uCM3MGqzGNd1/BuZVbF8AXBgROwPLgdM6KiBP0r2YbNbLt0n6Ltmwjt/LHaKZWYNIWTfgPEuOsnYEjgUuT9si6yR2QzplMnBCR+XkGXvhakkzyIZ3FHBCRMzr4DIzs6bQiVrsQEnTK7YnRcSkiu0fAv8C9E3b2wErImJt2l4I7NDRTfIMYv4u4BXg15X7IqI2ffTMzOqoE28mLI2IURs6IOk4YHFEzJA0pivx5HlP91benKCyFzAUeAzYrSs3NjOrN0GtBig/CPiQpLFkeXAb4CJgW0k9Um13R+DZjgrqsE03IvaIiD3Tz2HAaDyerpl1Bznf0e0oL0fENyJix4gYApwC/G9EfBy4m2x2HYDxwC0dhZTnQVr7m88E9uvsdWZmjaCc/9tEXwe+IulxsjbeKzq6IE+b7lcqNluAfYDnNjVCM7Oi1GMK9oi4B7gnrT9B9u0/tzxtun0r1teStfHe2JmbmJk1Srca8CZ1iugbEV8tKB4zs5pqtgFvqk3X0yMi1ko6qMiAzMxqJZuCvdFRvFW1mu4DZO23syRNAa4HVrUdjIib6hybmVmXdZuJKSv0ApaRdXdre183ACddM2tq9XiQ1lXVku7b0psLc3gz2baJukZlZlYjTVbRrZp0W4GtYYMvsDnpmlk3IFo2/R3cuqiWdBdFxLmFRWJmVmOie9V0myxUM7NOEvRoskbdakn38MKiMDOrg25V042IF4sMxMysHrrjK2NmZt1Wk+VcJ10zKy+xCUMp1pmTrpmVl9y8YGZWmKxHmpOumVlhmivlNl9zh5lZTUn5lo7LUS9JD0h6WNKjkr6V9g+VNE3S45KuldSzWjlOumZWYkLKt+SwBjgsIvYCRgBHS9ofuAC4MCJ2BpYDp1UrxEnXzEqr7e2FPEtHIrMybW6RliAbgfGGtH8ycEK1cpx0zazUWqRcCzBQ0vSK5fT2ZUlqlTQLWAzcBfwVWJGmYAdYCOxQLR4/SDOz8lKnputZGhGjqp0QEeuAEZK2BW4Ghnc2JCddMyutenWOiIgVku4GDgC2bZveDNgReLbatW5eMLNSq9WDNEnbpxouknoDRwLzgLuBE9Np44FbqpXjmq6ZlVoN39MdDExOs6S3ANdFxG8kzQV+Kek7wEPAFdUKcdI1s9IS0FqjHmkR8Qiw9wb2PwGMzluOk66ZlVqT9QJ20jWzMhNqso7ATrpmVmqu6ZqZFSR7Zay5sq6TrpmVV87BbIrkpGtmpebxdM3MCpINYt7oKN7KSdfMSs1vL5iZFajJWhecdC3z7AvL+fw5/8PiF19GgvEnHMRnTxnT6LCsnc+NO5RPnnAgRDD38ef4wrlXcfMlX2TrPr0AGNi/LzMffYpPfO2yBkfaPDabmq6kAK6OiE+k7R7AImBaRBxX5boxwFcj4jhJHwJ2jYjz6xVnu3uPAN4REbcVcb9m0trawrn//GH2Gv5OXl71KoeP/z6HjN6F4TsNbnRolgzevh+fPfkQ9j/5u7y65nV+9r1P85GjRjL29B++cc7kC/6J237/SAOjbC7N2KZbz1HGVgG7p9F4IBuRp+qQZ+1FxJSiEm4yAhhb4P2axtsH9mOv4e8EoG+fXgwb8nYWLXmpwVFZez16tNJryy1obW1hq149eb7iM+rbpxcHj3qvk26lnAOYF/mGQ72HdrwNODatjwOuaTsgabSk+yU9JOlPknZpf7GkUyVdktbfI+nPkmZL+o6klWn/GEn3SLpB0nxJVyuN0ybpbEkPSpojaVLF/nskXZAmmfuLpPenyeTOBU6WNEvSyXX9yzSxZ55bxuy/LGTkbu9udChWYdGSl/jRVVOZ/etvM/+33+Xvq1Zz97T5bxwfe8ie/P7Bx3h51asNjLL5KOdSlHon3V8Cp0jqBewJTKs4Nh94f0TsDZwNfK+Dsi4CLoqIPcimxKi0N3AWsCuwE3BQ2n9JROwbEbsDvYHKZo0eETE6XTcxIl5LcVwbESMi4tr2AUg6vW0qj6VLl3T4y3dHK19Zw6kTruC7X/4I22zdu+MLrDD9+vZm7MF7MOL4ibzvmG+yVa+enHTMvm8cP/EDI7nxjhkNjLD5ZM0Lm1FNNw2FNoSsltu+nbQfcL2kOcCFwG4dFHcAcH1a/0W7Yw9ExMKIWA/MSvcEODRNjTybbPK4ynvclH7OqDi/o99nUkSMiohRAwdun+eSbuX1tes4dcLlnHj0KD546IhGh2PtjBk9nKefW8ayFStZu249v777YUbvORSAAf36sM+uQ7jzj3MaHGXz2dxqugBTgB9Q0bSQfBu4O9VCPwj06sI91lSsrwN6pNr1T4ATU+34snb3WFN5fhfuXQoRwZnfuZr3Dnk7n//YYY0OxzZg4fMvMmqPofTecgsADtl3Fx578gUAjj98b+64bw5rXltbrYjNU5Nl3SKSzc/IZsucnd5MaNOPNx+snZqjnD8DHwWuBU7JcX5bgl0qaWuy6TRuqHI+wMtA3xxll860h5/gut8+yK47v4NDPpE9u/y3z32QIw/q6AuIFWXGo08zZepD3HPV11m3bj2PPLaQyTf/EYCPHDWSH06+s8ERNqfNrhtwRCwELt7Aoe+TTX3xb8CtOYo6C7hK0jeB24Gqj9bTxHGXAXOA54EHc9zjbmBCmmL5vA2165bV/iPew7JpP2p0GNaB8yfdxvmT/vGNxg+ecVEDoukeapVyJb0TuBIYBAQwKSIukjSArDI4BHgKOCkilm+0nIioUUj1JWkrYHVEhKRTgHERcXyj4tln5Ki47/48edyaxXb7fanRIVgnrHnsOta/srhLOfN9e+wdV065J9e5o3fadka1KdglDQYGR8RMSX3JngedQPZN/cWIOF/SBKB/RHx9Y+V0p7bMkcAl6bWvFcCnGxyPmTW5rLm2ZnOkLSLr4EVEvCxpHrADcDwwJp02GbgH6P5JNyL+AOzV6DjMrBvp3Hi6AyVNr9ieFBGTNlisNITsVdVpwKCUkCFryhxU7SbdJumamW2KTtRzl1ZrXnijvOzB/I3AWRHxd1Vk9dT8WbXNtohXxszMGkRI+ZZcpUlbkCXcqyOi7V3/F1J7b1u77+JqZTjpmlmpSfmWjsuRgCuAeRHxnxWHpgDj0/p44JZq5bh5wcxKq8b9Hg4CPgnMTq+VAvwrcD5wnaTTgKeBk6oV4qRrZuVWo6wbEfdVKe3wvOU46ZpZqW02g5ibmTWDJusF7KRrZiXWufd0C+Gka2al5uYFM7OCCNd0zcwK1WQ510nXzEquybKuk66ZldpmN4i5mVkjNVfKddI1s7JrsqzrpGtmpVXLQcxrxUnXzMrLnSPMzIrVZDnXSdfMyiz/AOVFcdI1s1JrspzrpGtm5VXjQcxrwtP1mFm5KefSUTHSzyQtljSnYt8ASXdJWpB+9u+oHCddMys15fxfDj8Hjm63bwIwNSKGAVPTdlVOumZWarWamDIi7gVebLf7eGByWp8MnNBROW7TNbPyErTkb9QdKGl6xfakiJjUwTWDImJRWn8eGNTRTZx0zazkcmfdpRExalPvEhEhKTo6z80LZlZabYOY16J5YSNekDQYIP1c3NEFTrpmVmo1enlhY6YA49P6eOCWji5w0jWzUqtVTVfSNcD9wC6SFko6DTgfOFLSAuCItF2V23TNrNRq1Q04IsZt5NDhnSnHSdfMSq3ZeqQ56ZpZaXXxIVldOOmaWal5EHMzsyI1V8510jWzcmuynOuka2ZlJk/BbmZWlLYeac3EnSPMzArkmq6ZlVqz1XSddM2s1PzKmJlZUdw5wsysOM34IM1J18xKzc0LZmYFck3XzKxATZZznXTNrOSaLOs66ZpZaQmarhuwIjqcvNI2QNIS4OlGx1EHA4GljQ7COqWsn9m7I2L7rhQg6Xayv08eSyPi6K7cLw8nXXsLSdO7Mg21Fc+fWffisRfMzArkpGtmViAnXWtvUqMDsE7zZ9aNuE3XzKxArumamRXISdfMrEBOuiUjaZ2kWZIeljRT0oFdKOtcSUfUMr7NkaSQdFXFdg9JSyT9poPrxrSdI+lDkibUO9aKe4+QNLao+21O3COtfFZHxAgASR8AzgMO2ZSCIuLsWga2GVsF7C6pd0SsBo4Enu1MARExBZhSj+A2YgQwCritwHtuFlzTLbdtgOVtG5K+JulBSY9I+lbaN0TSPEmXSXpU0p2SeqdjP5d0YlofK2m+pBmSLq6ogZ0j6WeS7pH0hKQzG/B7dge3Acem9XHANW0HJI2WdL+khyT9SdIu7S+WdKqkS9L6eyT9WdJsSd+RtDLtH5M+hxvSZ3W1lPWBlXR2+uznSJpUsf8eSRdIekDSXyS9X1JP4Fzg5PSt6eS6/mU2M0665dM7/YcyH7gc+DaApKOAYcBoslrMSEkHp2uGAT+OiN2AFcBHKwuU1Au4FDgmIkYC7btmDgc+kMqeKGmLuvxm3dsvgVPS33JPYFrFsfnA+yNib+Bs4HsdlHURcFFE7AEsbHdsb+AsYFdgJ+CgtP+SiNg3InYHegPHVVzTIyJGp+smRsRrKY5rI2JERFzbyd/VqnDSLZ/V6T+U4cDRwJWpVnNUWh4CZpIlymHpmicjYlZanwEMaVfmcOCJiHgybV/T7vitEbEmIpYCi4FBtfyFyiAiHiH7u47jH7+y9wOulzQHuBDYrYPiDgCuT+u/aHfsgYhYGBHrgVm8+VkeKmmapNnAYe3ucVP6uaHP3mrMbbolFhH3SxpIVjMVcF5EXFp5jqQhwJqKXevIakKd0f56//9qw6YAPwDGANtV7P82cHdEfDh9Hvd04R7/8Fmk2vVPgFER8TdJ5wC9NnCNP7sCuKZbYpKGA63AMuAO4NOStk7HdpD0tpxFPQbslBICgNv4Ns3PgG9FxOx2+/vx5oO1U3OU82febAI6Jcf5bQl2afr8T8xxzctA3xznWSc56ZZPW5vuLOBaYHxErIuIO8m+it6fvmLeQM7/qNIT988Dt0uaQfYf5Ev1Cb+80tf+izdw6PvAeZIeIl9N8yzgK5IeAXamg88iIlYAlwFzyP7xfTDHPe4GdvWDtNpzN2DLRdLWEbEytQ//GFgQERc2Oq7NkaStyNruQ9IpwLiIOL7RcVk+br+xvD4jaTzQk+xh3KUdnG/1MxK4JP0DuAL4dIPjsU5wTdfMrEBu0zUzK5CTrplZgZx0zcwK5KRrdVEx2tkcSdenJ+6bWlblGBCXS9q1yrljNmVkNUlPpY4kufa3O2dlJ+91jqSvdjZGKwcnXauXtu7IuwOvAWdUHpS0SW/ORMQ/RcTcKqeMATZ5OEuzenPStSL8Adg51UL/IGkKMFdSq6T/qBj57LMAylwi6TFJvwPe6DmXRsUaldaPVjZm8MOSpqYec2cAX0617PdL2l7SjekeD0o6KF27nbIR1R6VdDlZN+mqJP1K2Shrj0o6vd2xC9P+qZK2T/veI+n2dM0fUg9B28z5PV2rq1SjPQa4Pe3aB9g9Ip5MieuliNhX0pbAHyXdSTZS1i5kI2UNAuaSdaGtLHd7sl5WB6eyBkTEi5J+CqyMiB+k834BXBgR90l6F1mPrPcBE4H7IuJcSccCp+X4dT6d7tEbeFDSjRGxDOgDTI+IL0s6O5X9RbIJI8+IiAWS9iMb/+CwTfgzWok46Vq99E5dkSGr6V5B9rX/gYrRyo4C9mxrryUbg2AYcDBwTUSsA56T9L8bKH9/4N62siLixY3EcQRZd9a27W3S+AMHAx9J194qaflGrq90pqQPp/V3pliXAevJulwDXAXclO5xINnoYW3Xb5njHlZyTrpWL2/MYNEmJZ9VlbuAL0XEHe3Oq+U0MS3A/hHx6gZiyU3SGLIEfkBEvCLpHt46UlelSPdd0f5vYOY2XWukO4DPtQ16Lum9kvoA95LNWtAqaTBw6Aau/TNwsKSh6doBaX/70bHuBL7UtiGpLQneC3ws7TsG6N9BrP2A5SnhDierabdp4c2Ruz5G1mzxd+BJSf833UOS9urgHrYZcNK1RrqcrL12prIBvC8l+/Z1M7AgHbsSuL/9hRGxBDid7Kv8w7z59f7XwIfbHqQBZwKj0oO6ubz5FsW3yJL2o2TNDM90EOvtZGPTzgPOJ0v6bVYBo9PvcBjZVDcAHwdOS/E9CnhQGvPYC2ZmRXJN18ysQE66ZmYFctI1MyuQk66ZWYGcdM3MCuSka2ZWICddM7MC/X+DSRvgWhVSiQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt2VjHsfc5pY"
      },
      "source": [
        "We can now see that our Decision Tree model successfully classified 94% of the samples in both classes, benign (class 0) and malignant (class 1)\n",
        "\n",
        "Another quick way to check the accuracy, recall, and precision of a model on a test set is with `classification_report()`, which runs several metrics on both classes simultaneously."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jz0bpAN3cqmw",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "12f79f93-daab-4d7e-ca2a-336cdd3f6730"
      },
      "source": [
        "#Use classifiction_report() to print a report of several metrics for all classes at once\n",
        "#for both models\n",
        "\n",
        "report_dict = classification_report(y_test, preds, output_dict=True)\n",
        "pd.DataFrame(report_dict)\n",
        "\n",
        "# Source: https://www.statology.org/sklearn-classification-report/\n",
        "# Source : https://stackoverflow.com/questions/45003577/how-to-output-classification-report-of-sklearn-into-a-csv-file"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   0          1  accuracy   macro avg  weighted avg\n",
              "precision   0.927273   0.965909  0.951049    0.946591      0.951319\n",
              "recall      0.944444   0.955056  0.951049    0.949750      0.951049\n",
              "f1-score    0.935780   0.960452  0.951049    0.948116      0.951135\n",
              "support    54.000000  89.000000  0.951049  143.000000    143.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3a328cb-d805-4374-8acb-a456d029e3e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.927273</td>\n",
              "      <td>0.965909</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.946591</td>\n",
              "      <td>0.951319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.955056</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.949750</td>\n",
              "      <td>0.951049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.935780</td>\n",
              "      <td>0.960452</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>0.948116</td>\n",
              "      <td>0.951135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.951049</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>143.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3a328cb-d805-4374-8acb-a456d029e3e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3a328cb-d805-4374-8acb-a456d029e3e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3a328cb-d805-4374-8acb-a456d029e3e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "report_dict = classification_report(y_test, dum_preds, output_dict=True)\n",
        "pd.DataFrame(report_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "qfE0bVrxpSpv",
        "outputId": "4f8c4a17-8c4e-4090-9fc7-463312b2283c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0          1  accuracy   macro avg  weighted avg\n",
              "precision   0.0   0.622378  0.622378    0.311189      0.387354\n",
              "recall      0.0   1.000000  0.622378    0.500000      0.622378\n",
              "f1-score    0.0   0.767241  0.622378    0.383621      0.477514\n",
              "support    54.0  89.000000  0.622378  143.000000    143.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf959cb6-5a69-4da3-8c43-290e1b858fc1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.622378</td>\n",
              "      <td>0.622378</td>\n",
              "      <td>0.311189</td>\n",
              "      <td>0.387354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.622378</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.622378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.767241</td>\n",
              "      <td>0.622378</td>\n",
              "      <td>0.383621</td>\n",
              "      <td>0.477514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>54.0</td>\n",
              "      <td>89.000000</td>\n",
              "      <td>0.622378</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>143.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf959cb6-5a69-4da3-8c43-290e1b858fc1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf959cb6-5a69-4da3-8c43-290e1b858fc1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf959cb6-5a69-4da3-8c43-290e1b858fc1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnz0EbE6dbPR"
      },
      "source": [
        "You'll notice that each class has a different recall and precision.  f1-score, by the way, is the harmonic mean of the precision and recall.  \n",
        "\n",
        "classification_report also tells us the averages of the precisions, means, and f1-scores.  'support' is how many samples there are of each class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0GZG210h5y7"
      },
      "source": [
        "# Multi-class Metrics\n",
        "\n",
        "Precision, recall, and accuracy also extend to cases when we have more than 2 possible classes.  However, in order to know how to calculate precision and recall we have to decide which class is our positive class.  We also become interested in the most complex patterns of errors that can occur.  \n",
        "\n",
        "For examples, suppose we have a problem with 3 possbile classes.  We might ask: \n",
        "\n",
        "When our model misclassifies class 1 samples, is it more often classifying them as class 0, or class 2?  This my help us understand why it is making that kind of mistake and how we can improve performance.\n",
        "\n",
        "This is where confusion matrices become even more useful in understanding how our model is behaving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3pCVHISdXXb"
      },
      "source": [
        "# Summary\n",
        "\n",
        "Accuracy, precision, and recall all are metrics that give us different insights into how our model is performing in making predictions.  No one of them alone tells us everything, and different metrics are more or less important depending on our business problem.\n",
        "\n",
        "However, we need to measure all three to make sure our model is making useful predictions.  Two ways to do this quickly are with a confusion matrix and a classification report."
      ]
    }
  ]
}
